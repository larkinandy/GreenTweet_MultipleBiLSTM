{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and graph performance summary statistics #\n",
    "\n",
    "** Author: Andrew Larkin **, Oregon State University College of Public Health and Human Sciences <br>\n",
    "** Date created: ** January 5th, 2018\n",
    "\n",
    "### Summary ###\n",
    "For evaluating performance of candidate models in train, dev, test, and independent datasets.  Calculate confusion matrices of model-dataset combinations.  Graph precision and recall for each model-dataset combation and outcome.\n",
    "\n",
    "This script is divided into two parts:\n",
    "1) Calculate performance metrics and output to CSV\n",
    "2) Graph performance metrics and save to .eps file (or print to screen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and define global variables and constants ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as ps\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define input and output filepaths\n",
    "parentFolder = \"C:/Users/larkinan/Desktop/DBTraining/\"\n",
    "performFolder = parentFolder + \"modelTrainingPerformance/\" \n",
    "performCSV_Denorm = performFolder + \"ModelPerformance_v1.csv\"   # intermediate file containing precision and recall estimates to graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load performanceMeasuresFromCSV\n",
    "def loadPerformanceData(dataFilepath,debug=False):\n",
    "    rawData = ps.read_csv(dataFilepath)\n",
    "    \n",
    "    # Second step in case future versions need to process input data\n",
    "    processedData = rawData\n",
    "    \n",
    "    if(debug):\n",
    "        print(processedData.head())\n",
    "        keys = processedData.keys()\n",
    "        print(\"number of records: %i\" %len(processedData[keys[0]]))\n",
    "    \n",
    "    return(rawData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each subplot, setup graph properties including axis boundaries, titles, and reference lines ###\n",
    "**Inputs:** <br>\n",
    "- **tempAxis** (object) - matplotlib axis object for the current subplot <br>\n",
    "- **xDim** (2 element float array) - min and max boundaries for the x axis\n",
    "- **yDim** (2 element float array) - min and max boundaries for the y axis\n",
    "- **yLabel** (string) - optional label for the yaxis\n",
    "- **xLabel** (string) - optional label for the xaxis\n",
    "- **outcome** (string) - optional subplot title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setAxisProperties(tempAxis,xDim,yDim,yLabel=None,xLabel = None,title=None):\n",
    "    v_line = mlines.Line2D([0.7, 0.7], [0, 1], color='black',linestyle='dashed')\n",
    "    h_line = mlines.Line2D([0,1],[0.7,0.7],color='black',linestyle='dashed')\n",
    "    tempAxis.set_xlim(xDim)\n",
    "    tempAxis.set_ylim(yDim)\n",
    "    tempAxis.add_line(v_line)\n",
    "    tempAxis.add_line(h_line)\n",
    "    if(yLabel):\n",
    "        tempAxis.set_ylabel(yLabel)\n",
    "    if(xLabel): \n",
    "        tempAxis.set_xlabel(xLabel)\n",
    "    if(title):\n",
    "        tempAxis.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot subset for one outcome of interest.  ### <br>\n",
    "plot includes all models and datasets for the outcome.  Colors and markers correspond to dataset and model, respectively <br>\n",
    "\n",
    "**Inputs** <br>\n",
    "- **performData** (pandas dataframe) - contains denormalized records of the dataset.  Important keys in the dataset include: <br>\n",
    "    1) outcome - which outcome the record corresponds to <br>\n",
    "    2) dataset - which dataset the record corresponds to (e.g. train, dev, test, etc.) <br>\n",
    "    3) model - which model the record corresponds to <br>\n",
    "    4) precision <br>\n",
    "    5) recall <br>\n",
    "    \n",
    "    \n",
    "- **outcome** (string) - outcome of interest.  Used to screen dataset\n",
    "- **outcomeVar** (string) - key for the column in the dataset that contains the outcome label\n",
    "- **subPlotMatrix** (3 element int array) - dimensions of the master plot and which index to push the subplot\n",
    "- **xDim** (2 element float array) - min and max boundaries of the x-axis\n",
    "- **yDim** (2 element float array) - min and max boundaries of the y-axis\n",
    "- **colorVec** (string array) - colors to distinguish between origin datasets (e.g. train, dev,) in the subplot <br>\n",
    "- **markerVec** (string array) - markers to diistinguish between models in the subplot <br>\n",
    "\n",
    "**Outputs** <br>\n",
    "- **markerDict** (dict) - marker:model pairs.  Mostly for debug purposes\n",
    "- **colorDict** (dict) - color:dataset pairs.  Mostly for debug purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotByOutcome(performData,outcome,outcomeVar,subplotMatrix = [4,2,1],\n",
    "                  xDim = [0.4,1],yDim = [0.2,1],\n",
    "                  colorVec = ['red','blue','green','#a05195','#d45087','#f95d6a','#ff7c43','#ffa600'], \n",
    "                  markerVec = ['+','o','s','d','x','^'],debug=False):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # setup axis and graph properties\n",
    "    tempAxis = plt.subplot(subplotMatrix[0],subplotMatrix[1],subplotMatrix[2])\n",
    "    setAxisProperties(tempAxis,xDim,yDim,'Recall','Precision',outcome)\n",
    "    \n",
    "    # setup local variables \n",
    "    outcomeSubset = performData.loc[performData[outcomeVar] == outcome]  # data subset for the outcome of interest\n",
    "    dataOrigins = sorted(set(outcomeSubset['Dataset']))          # set of datasets\n",
    "    models = sorted(set(outcomeSubset['Model']))                 # set of models\n",
    "    compareLineX = [0,0]                                         # x coords for line comparing two models\n",
    "    compareLineY = [0,0]                                         # y coords for line comparing two models\n",
    "    modelsOfInterest = ['Whole','NoEmbed']                       # models to comapre\n",
    "    markerDict = {}                                              # store marker:model pairs\n",
    "    colorDict = {}                                               # store color:dataset pairs\n",
    "    \n",
    "    \n",
    "    # for each dataset and each model, plot the precision vs. recall value \n",
    "    # with the appropriate (color,symbol) type\n",
    "    for origin in dataOrigins:    \n",
    "        \n",
    "        # subset records to the current 'origin' dataset of interest\n",
    "        originSubset = outcomeSubset.loc[outcomeSubset['Dataset'] == origin]\n",
    "        datasetColor = colorVec[dataOrigins.index(origin)]\n",
    "        colorDict[origin] = datasetColor\n",
    "        \n",
    "        # for the current dataset, go thorugh each model type\n",
    "        for model in models:\n",
    "            \n",
    "            # only one datapoint for each model-dataset combination\n",
    "            dataPoint = originSubset.loc[originSubset['Model'] == model]\n",
    "            \n",
    "            # setup a line to compare difference in precision and recall \n",
    "            # between the worst- and best-performing models\n",
    "            if model in modelsOfInterest:\n",
    "                modelIndex = modelsOfInterest.index(model)\n",
    "                compareLineX[modelIndex] = float(dataPoint['Precision'])\n",
    "                compareLineY[modelIndex] = float(dataPoint['Recall'])\n",
    "            \n",
    "            \n",
    "            modelMarker = markerVec[models.index(model)]\n",
    "            markerDict[model] = modelMarker\n",
    "            plt.scatter(\n",
    "                dataPoint['Precision'], \n",
    "                dataPoint['Recall'],\n",
    "                marker = modelMarker,\n",
    "                color = datasetColor\n",
    "            )\n",
    "            \n",
    "        # add line comparing worst- and best-performing model for the current dataset\n",
    "        compare_line = mlines.Line2D(compareLineX,compareLineY,color=datasetColor)\n",
    "        tempAxis.add_line(compare_line)\n",
    "        \n",
    "        \n",
    "    # when debugging, push graph to screen rather than saving to file\n",
    "    if(debug):\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return(colorDict,markerDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot precision vs. recall performance for all outcomes, datasets, and models ###\n",
    "Graph consists of multiple subplots, with one subplot for each outcome.  Points are colored by originating dataset (e.g. train, dev, test), while markers correspond to model (e.g. whole model, model with no emoticons, etc.)\n",
    "\n",
    "**Inputs** <br>\n",
    "- **performData** (pandas dataframe) - contains all records and labels for all outcomes.  Keys include: <br>\n",
    "    1) outcome - which outcome the record corresponds to <br>\n",
    "    2) dataset - which dataset the record corresponds to (e.g. train, dev, test, etc.) <br>\n",
    "    3) model - which model the record corresponds to <br>\n",
    "    4) precision <br>\n",
    "    5) recall <br>\n",
    "\n",
    "- **xLims** (2 element float array) - x-axis boundaries <br>\n",
    "- **yLims** (2 element float array) - y-axis boundaries <br>\n",
    "- **title** (string) - optional graph title\n",
    "- **outputFilename** (string) - absolute filepath where the plot will be saved.  If none, plot is pushed to notebook <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrecisionRecall(performData,xLims,yLims,title=\"Precision vs. Recall\",outputFilename=None):\n",
    "    \n",
    "    \n",
    "    # local variable setup.  \n",
    "    fig = figure(num=None, figsize=(8, 16), dpi=160, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    uniqueOutcomes = set(performData['Outcome'])\n",
    "    \n",
    "    \n",
    "    index = 1        # subplot indeces start at 1, not 0\n",
    "    colorDict, marerDict = [{} for x in range(2)]\n",
    "    \n",
    "    for outcome in uniqueOutcomes:\n",
    "        colorDict, markerDict = plotByOutcome(\n",
    "            performData,\n",
    "            outcome,\n",
    "            'Outcome',\n",
    "            [4,2,index],\n",
    "            xLims[index-1],\n",
    "            yLims[index-1]\n",
    "        )\n",
    "        index+=1\n",
    "\n",
    "    if(not outputFilename):\n",
    "        print(colorDict)\n",
    "        print(markerDict)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        #plt.savefig(performFolder + \"ModelPerformance.eps\", bbox_inches=\"tight\")\n",
    "        plt.savefig(outputFilename,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createPerformanceGraphs(performCSV):\n",
    "    \n",
    "    performDataset = loadPerformanceData(performCSV,True)\n",
    "    \n",
    "    # plot graphs with different x- y-axis boundaries for each outcome\n",
    "    yLims = [[0.4,1],[0.4,1],[0.5,1],[0.2,1],[0.5,1],[0.7,1],[0.0,1]]\n",
    "    xLims = [[0.4,1],[0.7,1],[0.7,1],[0.7,1],[0.7,1],[0.7,1],[0.4,1]]\n",
    "    outputFilepath = performFolder + \"precRecallVaryingBound.eps\"\n",
    "    plotPrecisionRecall(performDataset,xLims,yLims,\"Precision vs. Recall with Varying Boundaries\",outputFilepath)\n",
    "    \n",
    "    # plot graphs with the same x- and y-axisboundaries for each outcome\n",
    "    yLims = [[0.0,1],[0.0,1],[0.0,1],[0.0,1],[0.0,1],[0.0,1],[0.0,1]]\n",
    "    xLims = [[0.4,1],[0.4,1],[0.4,1],[0.4,1],[0.4,1],[0.4,1],[0.4,1]]\n",
    "    outputFilepath = performFolder + \"precRecallFixedBound.eps\"\n",
    "    plotPrecisionRecall(performDataset,xLims,yLims,\"Precision vs. Recall with Set Boundaries\",outputFilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Outcome     Model   Dataset  Precision  Recall\n",
      "0   Aesthetic  Emoticon  Training       0.92    0.81\n",
      "1      Safety  Emoticon   NewYork       0.92    0.36\n",
      "2         Air  Emoticon  Training       0.89    0.76\n",
      "3  Greenspace  Emoticon  Training       0.88    0.92\n",
      "4   Aesthetic  Emoticon      Test       0.88    0.66\n",
      "number of records: 164\n"
     ]
    }
   ],
   "source": [
    "createPerformanceGraphs(performCSV_Denorm)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

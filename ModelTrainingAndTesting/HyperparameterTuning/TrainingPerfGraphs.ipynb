{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and graph performance summary statistics #\n",
    "\n",
    "** Author: Andrew Larkin **, Oregon State University College of Public Health and Human Sciences <br>\n",
    "** Date created: ** October 24, 2018\n",
    "\n",
    "### Summary ###\n",
    "Part of the hyperparameter tuning process, this script reads performance dictionaries in pickled format, calculates summary statistics, and graphs the Mathews Correlation Coefficient (MCC) and cost as a function of hyperparameter values and epoch number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and define global variables and constants ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define input and output filepaths\n",
    "parentFolder = \"C:/Users/larkinan/Desktop/DBTraining/\"\n",
    "performFolder = parentFolder + \"modelTrainingPerformance/\"\n",
    "\n",
    "# storage locations for performance dictionaries (pickled) for each hyperparameter to be tuned\n",
    "performancePickleParams = {\n",
    "    \"parentFolder\":performFolder,\n",
    "    \"learningRate\":performFolder + \"learningRate_Extended\",\n",
    "    \"batchSizeFolder\":performFolder + \"batchSize\",\n",
    "    \"postLSTMLayerSize\":performFolder + \"postLSTMLayerSize\",\n",
    "    \"postLSTMLayers\":performFolder + \"postLSTMLayers\",\n",
    "    \"keepProb\":performFolder + \"keepProb\",\n",
    "    \"hiddenLayerActivation\":performFolder + \"activationType\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pickled datasets of training model performance into memory\n",
    "\n",
    "def readPickledPerformanceDatasets(inFolder):\n",
    "    filesToRead = os.listdir(inFolder)\n",
    "    dictArray = []\n",
    "    for filename in filesToRead:\n",
    "        performDict = pickle.load(open(inFolder + \"/\" + filename,'rb'))\n",
    "        dictArray.append(performDict)\n",
    "    return(dictArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate mean and std dev of the cost function for training and dev sets ###\n",
    "**Inputs:** <br>\n",
    "- **performanceDictArray** (dict) - contains performance metrics at set epoch intervals for a single model. <br>\n",
    "- **epochVals** (integer array) - set of epoch steps as which performance metrics are calculated <br>\n",
    "\n",
    "**Outputs:** <br>\n",
    "- **meanTrainCost** (np float array) - mean cost for each epoch step in a random sample from the train set across multiple models trained with the same hyperparameters <br>\n",
    "- **stdDevTrainCost** (np float array) - std dev cost for each epoch step in a random sample from the train set across multiple models trained with the same hyperparameters <br>\n",
    "- **meanDevCost** (np float array) - mean cost for each epoch step in a random sample from the dev set across multiple models trained with the same hyperparameters <br>\n",
    "- **stdDevDevCost** (np float array) - std dev cost for each epoch step in a random sample from the dev set across multiple models trained with the same hyperparameters <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcSummaryStatsCost(performanceDictArray,epochVals):\n",
    "    numBatches = len(performanceDictArray)\n",
    "    numEpochs = len(epochVals)\n",
    "    \n",
    "    # np matrices containing cost values for all batches and all epochs\n",
    "    performanceTrainArray = np.zeros((numBatches,numEpochs))\n",
    "    performanceDevArray = np.zeros((numBatches,numEpochs))\n",
    "    \n",
    "    # for each batch, store cost values in the corresponding row\n",
    "    for batchNum in range(numBatches):\n",
    "        # for each epoch, store cost values in the corresponding column\n",
    "        for epochNum in range(numEpochs):\n",
    "            performanceTrainArray[batchNum,epochNum] = performanceDictArray[batchNum]['trainDict']['Cost'][epochNum]\n",
    "            performanceDevArray[batchNum,epochNum] = performanceDictArray[batchNum]['devDict']['Cost'][epochNum]       \n",
    "\n",
    "    #outputs\n",
    "    meanTrainCost = np.nanmean(performanceTrainArray,axis=0)\n",
    "    stdDevTrainCost = np.nanstd(performanceTrainArray,axis = 0)\n",
    "    meanDevCost = np.nanmean(performanceDevArray,axis=0)\n",
    "    stdDevDevCost = np.nanstd(performanceDevArray,axis = 0)\n",
    "    \n",
    "    return(meanTrainCost,stdDevTrainCost,meanDevCost,stdDevDevCost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate mean and std performance score (FScore or MCC) for a set of hyperparameters ###\n",
    "**Inputs:** <br>\n",
    "- **performanceDictArray** (dict) - contains performance metrics at set epoch intervals for a single model. <br>\n",
    "- **epochVals** (integer array) - set of epoch steps as which performance metrics are calculated <br>\n",
    "- **outComeIndex** (integer) - column containing the outcome of interest.  MCC Score is column 0, F1 Score is column 1 <br>\n",
    "\n",
    "**Outputs:** <br>\n",
    "- **meanTrainVals** (np float array) - mean performance score for each epoch step in a random sample from the train set aross multiple models trained with the same hyperparameters <br>\n",
    "- **stdDevTrainVals** (np float array) - std dev performance core for each epoch step in a random sample from the train set across multiple models trained with the same hyperparameters <br>\n",
    "- **meanDevVals** (np float array) - mean performance score for each epoch step in a random sample from the dev set aross multiple models trained with the same hyperparameters <br>\n",
    "- **stdDevTrainVals** (np float array) - std dev performance core for each epoch step in a random sample from the dev set across multiple models trained with the same hyperparameters <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcSummaryStatsSingleOutcome(performanceDictArray,epochVals,outcomeIndex):\n",
    "    numBatches = len(performanceDictArray)\n",
    "    numEpochs = len(epochVals)\n",
    "    \n",
    "    # np matrices containing performance scores for all batches and all epochs\n",
    "    performanceTrainArray = np.zeros((numBatches,numEpochs))\n",
    "    performanceDevArray = np.zeros((numBatches,numEpochs))\n",
    "    \n",
    "    # for each batch, store performance score in the corresponding row\n",
    "    for batchNum in range(numBatches):\n",
    "        # for each epoch, store performance score in the corresponding column\n",
    "        for epochNum in range(numEpochs):\n",
    "            performanceTrainArray[batchNum,epochNum] = performanceDictArray[batchNum]['trainDict']['F1Score'][epochNum][outcomeIndex][0]\n",
    "            performanceDevArray[batchNum,epochNum] = performanceDictArray[batchNum]['devDict']['F1Score'][epochNum][outcomeIndex][0]        \n",
    "            \n",
    "    # outputs\n",
    "    meanTrainVals = np.nanmean(performanceTrainArray,axis=0)\n",
    "    stdDevTrainVals = np.nanstd(performanceTrainArray,axis = 0)\n",
    "    meanDevVals = np.nanmean(performanceDevArray,axis=0)\n",
    "    stdDevDevVals = np.nanstd(performanceDevArray,axis = 0)\n",
    "    \n",
    "    return(meanTrainVals,stdDevTrainVals,meanDevVals,stdDevDevVals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caulcate summary stats for a single parameter value that's being tuned ### \n",
    "**Inputs** <br>\n",
    "- **summaryStatsDict** (dictionary) - contains performance of training and dev sets for the hyperparameter being tuned\n",
    "    - 'trainDict' - dictionary with cost and performance metrics based on evaluating a sample of the train set\n",
    "    - 'devDict' - dictionary with cost and performance metrics based on evaluting a sample of the dev set\n",
    "    - 'epochVals' - epoch steps at which cost and performance metrics were calculated\n",
    "- **performanceDictArray** (dictionary) - contains performance metrics at set epoch intervals for a single model. <br>\n",
    "\n",
    "No outputs.  Rather, the function appends data in the summaryStatsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcSummaryStatsSingleParamValue(summaryStatsDict,performanceDictArray):\n",
    "    epochVals = summaryStatsDict['epochVals']\n",
    "    numBatches = len(performanceDictArray)\n",
    "    epochVals.sort()\n",
    "    \n",
    "    outcomeMeanNames = summaryStatsDict['trainDict']['outcomeNames']\n",
    "    outcomeDevNames = summaryStatsDict['trainDict']['outcomeDevNames']\n",
    "    \n",
    "    # column 1 is mean, column 2 is std dev, rows are different outcomes\n",
    "    \n",
    "    # for each outcome of interest except for cost, calculate mean and std dev for train and dev samples \n",
    "    for index in range(len(outcomeNames)):\n",
    "        meanTrain, stdDevTrain, meanDev, stdDevDev = calcSummaryStatsSingleOutcome(performanceDictArray,epochVals,index)\n",
    "        \n",
    "        # if outcome of interest is not yet in the summary stats dict, create a key and instantiate.  Otherwise append to it.\n",
    "        if(outcomeMeanNames[index] not in summaryStatsDict['trainDict'].keys()):\n",
    "            summaryStatsDict['trainDict'][outcomeMeanNames[index]] = [meanTrain]\n",
    "            summaryStatsDict['trainDict'][outcomeDevNames[index]] = [stdDevTrain]\n",
    "            summaryStatsDict['devDict'][outcomeMeanNames[index]] = [meanDev]\n",
    "            summaryStatsDict['devDict'][outcomeDevNames[index]] = [stdDevDev]\n",
    "            \n",
    "        else:   \n",
    "            summaryStatsDict['trainDict'][outcomeMeanNames[index]].append([meanTrain])\n",
    "            summaryStatsDict['trainDict'][outcomeDevNames[index]].append([stdDevTrain])\n",
    "            summaryStatsDict['devDict'][outcomeMeanNames[index]].append([meanDev])\n",
    "            summaryStatsDict['devDict'][outcomeDevNames[index]].append([stdDevDev])\n",
    "     \n",
    "    # calculate mean and std dev of cost function for train and dev samples \n",
    "    meanTrain,stdDevTrain, meanDev, stdDevDev = calcSummaryStatsCost(performanceDictArray,epochVals)\n",
    "    \n",
    "    # it cost is not yet in summary stats dict, create a key and instantiate.  Otherwise, append to it.\n",
    "    if('cost' not in summaryStatsDict['trainDict'].keys()):\n",
    "        summaryStatsDict['trainDict']['cost'] = [meanTrain]\n",
    "        summaryStatsDict['trainDict']['costErr'] = [stdDevTrain]\n",
    "        summaryStatsDict['devDict']['cost'] = [meanDev]\n",
    "        summaryStatsDict['devDict']['costErr'] = [stdDevDev]\n",
    "    else:\n",
    "        summaryStatsDict['trainDict']['cost'].append([meanTrain])\n",
    "        summaryStatsDict['trainDict']['costErr'].append([stdDevTrain])\n",
    "        summaryStatsDict['devDict']['cost'].append([meanDev])\n",
    "        summaryStatsDict['devDict']['costErr'].append([stdDevDev])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create subplot to fit within a series of plots.  Each subplot contains multiple values of a single hyperparameter ###\n",
    "**Inputs:**<br>\n",
    "- **dataDict** (dict) - dictionary containing data to graph <br>\n",
    "- **yParam** (string) - name of key that corresponds to y-value to graph <br>\n",
    "- **errParam** (string) - name of key that corresponds to std err tograph <br>\n",
    "- **colorVec** (string array) - hexadecimal values for colors to distinguish between parameter values <br>\n",
    "- **subplotIndex** (int) - which subplot space within the entire plot area to create the graph <br>\n",
    "- **yLabel** (string) - y axis label <br>\n",
    "- **xLabel** (string) - x axis label <br>\n",
    "- **subplotTitle** (string) - title for subplot <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createSubplot(dataDict,yParam,errParam,colorVec,subplotIndex,yLabel,xLabel,subplotTitle):\n",
    "    xVals = dataDict['epoch']\n",
    "    yVals = dataDict[yParam]\n",
    "    errVals = dataDict[errParam]\n",
    "    paramVals = dataDict[dataDict['paramName']]\n",
    "    xMax = max(xVals) + 10\n",
    "    \n",
    "    tempAxis = plt.subplot(8,2,subplotIndex)\n",
    "    tempAxis.set_xlim([0,xMax])\n",
    "    tempAxis.set_ylim([0,1.1])\n",
    "    print(xMax)\n",
    "    tempAxis.set_title(subplotTitle)\n",
    "    if(1>2):\n",
    "        print('a')\n",
    "    #if(xLabel == None):\n",
    "    #    plt.setp(tempAxis.get_xticklabels(),visible=False)\n",
    "    else:\n",
    "        plt.xlabel(xLabel)\n",
    "    if(yLabel == None):\n",
    "        plt.setp(tempAxis.get_yticklabels(), visible=False)\n",
    "    else:\n",
    "        plt.ylabel(yLabel)\n",
    "    for i in range(len(paramVals)):\n",
    "        currYVals =  np.asarray(yVals[i])\n",
    "        currYVals = currYVals.reshape((len(xVals),))\n",
    "        yErrVals = np.asarray(errVals[i]).reshape((len(xVals),))\n",
    "        currColor = colorVec[i]\n",
    "        #marker = 'o'\n",
    "        plt.plot( xVals, currYVals, marker='None', markerfacecolor=currColor, label = paramVals[i], alpha = 0.8, color=currColor, linewidth=1)\n",
    "        #plt.errorbar(xVals, currYVals.tolist(), yerr=np.asarray(yErrVals).tolist(),color = currColor,alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print model params on output figure.  Not used in current version but retained for optional future use.\n",
    "\n",
    "def printModelParams(dataDict):\n",
    "    testParam = dataDict['paramName']\n",
    "    paramsInDict = dataDict.keys()\n",
    "    modelParams = ['mini_batch_size', \n",
    "                   'learning_rate', \n",
    "                   'momentum',\n",
    "                   'num_outcomes',\n",
    "                   'postLSTM_layer_size',\n",
    "                   'postLSTM_layers',\n",
    "                   'pre_softmax_layer_size',\n",
    "                   'keep_prob', \n",
    "                   'hidden_layer_activation',\n",
    "                   ]\n",
    "    outputText = \"Other Tunable Model Params: \\n\"\n",
    "    for printParam in modelParams:\n",
    "        if printParam != testParam and printParam in paramsInDict:\n",
    "            outputText += printParam + \": \" + str(dataDict[printParam]) + \"\\n\"\n",
    "    plt.figtext(0.1,-0.18,outputText,horizontalalignment='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create all subplots for a figure to evaluate model performance of various values for a single hyperparameter ###\n",
    "**Inputs:**<br>\n",
    "- **statsDict** (dict) - dictionary containing values to plot <br>\n",
    "- **outputFilepath** (string) - filepath where output figure file should be saved <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createGraphs(statsDict,outputFilepath):\n",
    "    trainDict = statsDict['trainDict']\n",
    "    devDict = statsDict['devDict']\n",
    "    fig = figure(num=None, figsize=(10, 18), dpi=160, facecolor='w', edgecolor='k')\n",
    "    fig.suptitle(trainDict['paramName'] + \" Performance\", fontsize=16)\n",
    "    colorVec = ['#003f5c','#2f4b7c','#665191','#a05195','#d45087','#f95d6a','#ff7c43','#ffa600']\n",
    "    epochVals = trainDict['epoch']\n",
    "    maxEpoch = max(trainDict['epoch'])\n",
    "    stepLen = (maxEpoch)/(len(trainDict['epoch']))\n",
    "    numParams = len(trainDict['cost'][0])\n",
    "    plt.xticks(np.arange(0, maxEpoch + 10, step=stepLen))\n",
    "    outcomeNames = copy.deepcopy(statsDict['trainDict']['outcomeNames'])\n",
    "    outcomeNames.append('cost')\n",
    "    devNames = statsDict['trainDict']['outcomeDevNames']\n",
    "    devNames.append('costErr')\n",
    "    for index in range(len(outcomeNames)):\n",
    "        currOutcome = outcomeNames[index]\n",
    "        currDev = devNames[index]\n",
    "        createSubplot(trainDict,currOutcome,currDev,colorVec,index*2+1,currOutcome,None,\"Training \" + currOutcome)\n",
    "        createSubplot(devDict,currOutcome,currDev,colorVec,(index+1)*2,currOutcome,None,\"Dev \" + currOutcome)\n",
    "    fig.legend(bbox_to_anchor=(0.4, 0.18, 0, 0),loc='lower center', ncol=numParams)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #printModelParams(trainDict) # currently not used.  Retained for optional future functionality\n",
    "    \n",
    "    plt.savefig(outputFilepath, bbox_inches=\"tight\")\n",
    "    \n",
    "    #plt.show() # only use for debugging purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from hard drive\n",
    "datasets = readPickledPerformanceDatasets(performancePickleParams['learningRate'])\n",
    "\n",
    "modelParam = 'learning_rate'\n",
    "uniqueParams = []\n",
    "for dataset in datasets:\n",
    "    paramVal = dataset['modelParams'][modelParam]\n",
    "    if(paramVal not in uniqueParams):\n",
    "        uniqueParams.append(paramVal)\n",
    "\n",
    "epochVals = list(set(datasets[0]['trainDict']['EpochNum']))\n",
    "epochVals.sort()\n",
    "outcomeNames = ['m_nature','m_safety','m_beauty','m_exercise','m_social','m_air','m_other']\n",
    "outcomeDevNames = ['sd_nature','sd_safety','sd_beauty','sd_exercise','sd_social','sd_air','sd_other']\n",
    "trainDict = {\n",
    "    'datasetName':'train',\n",
    "    'paramName':'learning_rate',\n",
    "    'epoch':epochVals,\n",
    "    'outcomeNames':outcomeNames,\n",
    "    'outcomeDevNames':outcomeDevNames,\n",
    "    'learning_rate':uniqueParams\n",
    "}\n",
    "devDict = {\n",
    "    'datasetName':'dev',\n",
    "    'paramName':'learning_rate',\n",
    "    'epoch':epochVals,\n",
    "    'outcomeNames':outcomeNames,\n",
    "    'outcomeDevNames':outcomeDevNames,\n",
    "    'learning_rate':uniqueParams\n",
    "}   \n",
    "\n",
    "\n",
    "summaryStatsDict = {'trainDict':trainDict,'devDict':devDict,'epochVals':epochVals,'numBatches':10}\n",
    "\n",
    "for uniqueParam in uniqueParams:\n",
    "    paramDatasetSubsets = []\n",
    "    for dataset in datasets:\n",
    "        paramVal = dataset['modelParams'][modelParam]\n",
    "        if(paramVal == uniqueParam):\n",
    "            paramDatasetSubsets.append(dataset)\n",
    "    calcSummaryStatsSingleParamValue(summaryStatsDict,paramDatasetSubsets)\n",
    "\n",
    "    \n",
    "createGraphs(summaryStatsDict,\"C:/users/larkinan/desktop/testPerformanceGraphsv_Extended.eps\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
